产品侧（终端用户视角）

| 产品入口 | 功能 | 模型系列 | 模态 | 版本 | 程序入口 | 组织 | 推理类型 | 规模/精度 | 备注 |
|---|---|---|---|---|---|---|---|---|---|
| DeepSeek 聊天官网 | 日常对话 | DeepSeek-V3 | 纯文本 | 2024-12 | Web、微信小程序、手机 App | 深度求索 | 非推理（快） | 671B-MoE / INT8 | 通用场景默认模型 |
| DeepSeek 聊天官网 | 深度思考 | DeepSeek-R1 | 纯文本 | 2025-01 | Web、微信小程序、手机 App | 深度求索 | 推理（Long-CoT） | 671B-MoE / INT8 | 开「深度思考」即走 R1 |
| DeepSeek 绘图页 | 文生图 | Janus-Pro-7B | 文本→图像 | 2025-01 | Web、PC 客户端 | 深度求索 | 非推理（扩散） | 7B / FP16 | 独立入口，暂不支持 API |
| 小程序「深小问」 | 语音对话 | DeepSeek-V3-TTS | 文本↔语音 | 2025-02 | 微信小程序 | 深度求索 | 非推理 | 1.2B / INT8 | 免费额度 200 次/日 |

开发侧（API / 本地部署视角）

| base_id | model_name | 能力关键词 | 上下文长度 | 最大输出 | 是否含思维链 | 单价 (input/output) | 本地可部署 | 许可证 | 备注 |
|---|---|---|---|---|---|---|---|---|---|
| v3 | deepseek-chat | 通用对话、代码、工具调用 | 128 k | 4 k | 否 | 0.0003 $/0.0003 $/1k | ✅ 7B-70B 蒸馏 | MIT | 默认 API 模型 |
| r1 | deepseek-reasoner | 数学、逻辑、代码推理 | 128 k | 8 k | 是（流式 reasoning_content） | 0.0009 $/0.0009 $/1k | ✅ 1.5B-70B 蒸馏 | MIT | 同权重长链模式 |
| janus-pro-7b | janus-pro-7b | 文生图 & 图理解 | 8 k | 2 k | 否 | 暂未公开 | ✅ 7B | MIT | 视觉编码器 448×448 |
| embedding | deepseek-embedding | 向量化 | 2 k | 2048 dim | — | 0.0001 $/1k | ✅ 1.5B | MIT | 维度 2048，余弦归一化 |
| tts-1 | deepseek-tts | 文本→语音 | 4 k | 音频 10 min | — | 0.015 $/1k 字符 | ✅ 1.2B | MIT | 仅中文，实时率 < 0.1 |

说明
1. base_id：对应官方  /v1/models  返回的  id  前缀，用于脚本批量调用。
2. model_name：实际传给  model="xxx"  的字符串，大小写敏感。
3. 单价为 2025-06 官方美元报价，MTok=1000 tokens；TTS 按字符计费。
4. 「本地可部署」栏：✅ 表示已公开 HuggingFace 权重，可离线运行；尺寸栏给出常见蒸馏规模。
5. 全部模型遵循 MIT 协议，可商用、可二次分发，只需保留版权文件。

和kimi的差异，可以一句话总结为：
 - DeepSeek：V3 与 R1 是两条独立基座权重，产品里用「深度思考」开关做模型级路由；开发者调 API 时必须显式换 model_name 才能切换。
 - Kimi：K2 与 K2-Thinking 是同一基座的两份训练权重，产品里用「深度思考」开关只是打开长链推理模式；开发者仍传同一  base_id="k2" ，仅改  model="kimi-k2-thinking"  即可，无需换基座。
 
因此：
- DeepSeek 的「深度思考」= 换模型；
- Kimi 的「深度思考」= 同一模型换推理策略。